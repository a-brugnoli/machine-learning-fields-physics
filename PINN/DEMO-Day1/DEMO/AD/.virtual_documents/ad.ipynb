





# At the start of your code
device = torch.device("cpu" if not torch.cuda.is_available() else "cuda")


import torch

def gradients(outputs, inputs):
    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)

# Define a vector input with requires_grad=True
x = torch.tensor([[2.0], [3.0], [4.0]], requires_grad=True)  

# Define the function with vector output
f1 = x[0]**2        # f1(x1) = x1^2
f2 = torch.exp(x[1]) # f2(x2) = e^x2
f3 = torch.sin(x[2]) # f3(x3) = sin(x3)
f = torch.stack([f1, f2, f3])  # Stack outputs to form a vector function
df = gradients(f, x)
df



import numpy as np

x = np.array([[2.0], [3.0], [4.0]], dtype=float)

# NumPy to PyTorch
y = torch.from_numpy(x)

#Set this array to differentiable
y=y.requires_grad_()
print(y.requires_grad_)
print(y.requires_grad)


# ## Create a Tensor with requires Grad true
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)


#If you already have a tensor but it was created without requires_grad=True, 
#you can enable it like this:

x = torch.tensor([1.0, 2.0, 3.0])
x = x.detach().requires_grad_()  # Detach and set requires_grad=True

print(x.requires_grad)  # Output: True


# Why requires_grad=True is useful

import torch
x = torch.tensor([2.0], requires_grad=True)  
f = x**2 + 3*x + 2
f.backward()
# Print the gradient
print("Gradient at x=2:", x.grad)  



import torch
xy = torch.tensor([2.0, 3.0], requires_grad=True)  

# Define the function f(x, y) = x^2 + y^2 + 3xy
f = xy[0]**2 + xy[1]**2 + 3 * xy[0] * xy[1]

f.backward()

# Print gradients
print("Gradient (df/dx, df/dy):", xy.grad)  






import torch
torch.manual_seed(1234)


A=torch.randint(3, 10, (3, 4))
B=torch.randint(3, 10, (4, 3))
print(f"A: {A} B:{B}")




torch.matmul(A, B)


C= torch.einsum("ij, jk -> ik", A, B)
C


torch.manual_seed(1234)
A=torch.randint(3, 10, (3, 4, 3))
B=torch.randint(3, 10, (3, 3, 4))
A




B


C = torch.einsum("bij, bjk->bik", A,B)
C


Ct = torch.matmul(A, B)


Ct






import torch
import torch.nn as nn 
from torch.nn.parameter import Parameter 
import numpy as np
import matplotlib.pyplot as plt

'''
clu = x * sigmoid(x) = (1/ (1 + exp(-x)))
'''


def caf(x):
    return x * (1.0/(1.0 + torch.exp(-x)))


x = torch.linspace(-10, 10, 100).view((-1, 1))
y = caf(x)
plt.plot(x, y, "-r")


class CAF(nn.Module):
    
    def __init__(self):
        super().__init__()       
    
    def forward(self, x):
        return caf(x)
    
custom_af = CAF()

Net = torch.nn.Sequential(
     CAF()
     )

y = Net(x)

plt.plot(y.detach().numpy())


from torchsummary import summary


class CAF(nn.Module):
    def __init__(self):
        super().__init__()
        self.a = nn.Parameter(torch.Tensor([0.1]), requires_grad=True)
        self.N = 10.0
    
    def forward(self, x):
        return  self.a * caf(x)
    
custom_af = CAF()

Net = torch.nn.Sequential()
Net.add_module("Linear-1", torch.nn.Linear(1, 100))
Net.add_module("Customized AF",  CAF())
Net.add_module("Linear-2",   torch.nn.Linear(100, 1))
y = Net(x)

for name, params in Net.named_parameters():
    if params.requires_grad:
        print(f"name: {name}")
        print(f" Shape: {params.size()}")

plt.plot(y.detach().numpy())





# In TensorFlow
import tensorflow as tf
import numpy as np
x = np.array([3.0, 4.0, 6.0], dtype=float)
x_tensor = tf.Variable(x)

def fun_g2(x_tensor):
    with tf.GradientTape(persistent=True) as f:
        f.watch(x_tensor)
        with tf.GradientTape(persistent=True) as g:
            g.watch(x_tensor)
            y = tf.exp(x_tensor)
        dy_dx = g.gradient(y, x_tensor)
    d2y_dx2 = f.gradient(dy_dx, x_tensor)
    return d2y_dx2

d2y_dx2 = fun_g2(x_tensor)

d2y_dx2.numpy()





import jax
import jax.numpy as jnp
vector_fn = lambda x: jnp.sum(x**2, axis=-1)  # Sum over each row
grad_fn = jax.vmap(jax.grad(vector_fn))  # Vectorized gradient computation
X = jnp.array([[1.0, 2.0], [3.0, 4.0]])  # 2D input
grad_X = grad_fn(X)
print(grad_X)


from jax import random
from jax.nn import tanh
from jax import numpy as jnp
from jax import vmap, value_and_grad, jit

def get_random_layer_params(m, n, random_key, scale=0.01):
    w_key, b_key = random.split(random_key)
    weights = 1/(jnp.sqrt(m+n)) * random.normal(w_key, (n, m))
    biases = jnp.zeros((n,)) 
    return weights, biases

def get_init_network_params(sizes, ran_key):
    keys = random.split(ran_key, len(sizes))
    return [get_random_layer_params(m, n, k) \
            for m, n, k in zip(sizes[:-1], sizes[1:], keys)]

def feedforward_prediction(params, x):     
    for w, b in params[:-1]:
        outputs = jnp.dot(w, x) + b  
        x = tanh(outputs)  
    w_final, b_final = params[-1] 
    final_outputs = jnp.dot(w_final, x) + b_final 
    return final_outputs  


batched_prediction = vmap(feedforward_prediction, in_axes=(None, 0))

@jit
def mse_loss(params, x, y):
    preds = batched_prediction(params, x)
    diff = preds - y
    return jnp.sum(diff*diff)/preds.shape[0]

@jit
def update(params, x, y, learning_rate):
    l, grads = value_and_grad(mse_loss)(params, x, y)
    return [(w - learning_rate * dw, b - learning_rate * db) 
            for (w, b), (dw, db) in zip(params, grads)], l



def f(x):
    return x**2

SEED = 1234
key = random.PRNGKey(SEED)
Niter = 100000
lr = 1e-02

num_features = 1
num_traget = 1
num_batches = 1000
layers = [1] + [32]*2 + [1]
ran_key, func_key = random.split(key)
params = get_init_network_params(layers, ran_key)


x_train = jnp.linspace(-1, 1, num_batches)
x_train = x_train.reshape((num_batches, num_features))
y_train = f(x_train)

for it in range(0, Niter):
    params, loss = update(params, x_train, y_train, lr)
    print(f"{it=} and {loss=}\n")
    



